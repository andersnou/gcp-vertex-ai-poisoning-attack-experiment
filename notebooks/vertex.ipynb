{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "# The project and bucket are for experiments below.\n",
    "PROJECT_ID = \"playground-anders\"  # @param {type:\"string\"}\n",
    "BUCKET_URI = \"gcp-vertex-ai-poisoning-attack\"  # @param {type:\"string\"}\n",
    "\n",
    "# You can choose a region from https://cloud.google.com/about/locations.\n",
    "# Only regions prefixed by \"us\", \"asia\", or \"europe\" are supported.\n",
    "REGION = \"europe-west4\"  # @param {type:\"string\"}\n",
    "REGION_PREFIX = REGION.split(\"-\")[0]\n",
    "assert REGION_PREFIX in (\n",
    "    \"us\",\n",
    "    \"europe\",\n",
    "    \"asia\",\n",
    "), f'{REGION} is not supported. It must be prefixed by \"us\", \"asia\", or \"europe\".'\n",
    "\n",
    "! gcloud config set project $PROJECT_ID\n",
    "\n",
    "STAGING_BUCKET = os.path.join(BUCKET_URI, \"temporal\")\n",
    "CHECKPOINT_BUCKET = os.path.join(BUCKET_URI, \"ckpt\")\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=STAGING_BUCKET)\n",
    "\n",
    "# Download config files.\n",
    "CONFIG_DIR = os.path.join(BUCKET_URI, \"config\")\n",
    "! wget https://raw.githubusercontent.com/tensorflow/models/master/official/vision/configs/experiments/retinanet/coco_spinenet49_gpu_multiworker_mirrored.yaml\n",
    "! gsutil cp coco_spinenet49_gpu_multiworker_mirrored.yaml $CONFIG_DIR/\n",
    "\n",
    "! wget https://raw.githubusercontent.com/tensorflow/models/master/official/vision/configs/experiments/retinanet/coco_spinenet96_gpu_multiworker_mirrored.yaml\n",
    "! gsutil cp coco_spinenet96_gpu_multiworker_mirrored.yaml $CONFIG_DIR/\n",
    "\n",
    "! wget https://raw.githubusercontent.com/tensorflow/models/master/official/vision/configs/experiments/retinanet/coco_spinenet143_gpu_multiworker_mirrored.yaml\n",
    "! gsutil cp coco_spinenet143_gpu_multiworker_mirrored.yaml $CONFIG_DIR/\n",
    "\n",
    "! wget https://raw.githubusercontent.com/tensorflow/models/master/official/projects/yolo/configs/experiments/yolov4/detection/scaled_yolov4_1280_gpu.yaml\n",
    "! gsutil cp scaled_yolov4_1280_gpu.yaml $CONFIG_DIR/\n",
    "\n",
    "! wget https://raw.githubusercontent.com/tensorflow/models/master/official/projects/yolo/configs/experiments/yolov7/detection/yolov7_gpu.yaml\n",
    "! gsutil cp yolov7_gpu.yaml $CONFIG_DIR/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OBJECTIVE = \"iod\"\n",
    "\n",
    "# Data converter constants.\n",
    "DATA_CONVERTER_JOB_PREFIX = \"data_converter\"\n",
    "DATA_CONVERTER_CONTAINER = f\"{REGION_PREFIX}-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/data-converter\"\n",
    "DATA_CONVERTER_MACHINE_TYPE = \"n1-highmem-4\"\n",
    "\n",
    "\n",
    "# Training constants.\n",
    "TRAINING_JOB_PREFIX = \"train\"\n",
    "TRAIN_CONTAINER_URI = f\"{REGION_PREFIX}-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/tfvision-oss\"\n",
    "TRAIN_MACHINE_TYPE = \"n1-highmem-4\"\n",
    "\n",
    "TRAIN_NUM_GPU = 2\n",
    "TRAIN_SPINENET49_CONFIG = os.path.join(\n",
    "    CONFIG_DIR, \"coco_spinenet49_gpu_multiworker_mirrored.yaml\"\n",
    ")\n",
    "TRAIN_SPINENET96_CONFIG = os.path.join(\n",
    "    CONFIG_DIR, \"coco_spinenet96_gpu_multiworker_mirrored.yaml\"\n",
    ")\n",
    "TRAIN_SPINENET143_CONFIG = os.path.join(\n",
    "    CONFIG_DIR, \"coco_spinenet143_gpu_multiworker_mirrored.yaml\"\n",
    ")\n",
    "TRAIN_YOLOV4_CONFIG = os.path.join(CONFIG_DIR, \"scaled_yolov4_1280_gpu.yaml\")\n",
    "TRAIN_YOLOV7_CONFIG = os.path.join(CONFIG_DIR, \"yolov7_gpu.yaml\")\n",
    "\n",
    "# Evaluation constants.\n",
    "EVALUATION_METRIC = \"AP50\"\n",
    "\n",
    "# Export constants.\n",
    "EXPORT_JOB_PREFIX = \"export\"\n",
    "EXPORT_CONTAINER_URI = f\"{REGION_PREFIX}-docker.pkg.dev/vertex-ai-restricted/vertex-vision-model-garden-dockers/tfvision-model-export\"\n",
    "EXPORT_MACHINE_TYPE = \"n1-highmem-4\"\n",
    "\n",
    "# Prediction constants.\n",
    "# You can deploy models with\n",
    "#   pre-build-dockers: https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers.\n",
    "#   and optimized tensorflow runtime dockers: https://cloud.google.com/vertex-ai/docs/predictions/optimized-tensorflow-runtime.\n",
    "# The example in this notebook uses optimized tensorflow runtime dockers.\n",
    "# You can adjust accelerator types and machine types to get faster predictions.\n",
    "PREDICTION_CONTAINER_URI = f\"{REGION_PREFIX}-docker.pkg.dev/vertex-ai-restricted/prediction/tf_opt-gpu.2-11:latest\"\n",
    "\n",
    "PREDICTION_MACHINE_TYPE = \"n1-standard-4\"\n",
    "UPLOAD_JOB_PREFIX = \"upload\"\n",
    "DEPLOY_JOB_PREFIX = \"deploy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define common libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from io import BytesIO\n",
    "from typing import Dict, List, Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import yaml\n",
    "from google.cloud import aiplatform\n",
    "from google.protobuf import json_format\n",
    "from google.protobuf.struct_pb2 import Value\n",
    "from PIL import Image, ImageColor, ImageDraw, ImageFont\n",
    "\n",
    "\n",
    "def get_job_name_with_datetime(prefix: str):\n",
    "    return prefix + datetime.now().strftime(\"_%Y%m%d_%H%M%S\")\n",
    "\n",
    "\n",
    "def predict_custom_trained_model(\n",
    "    project: str,\n",
    "    endpoint_id: str,\n",
    "    instances: Union[Dict, List[Dict]],\n",
    "    location: str = \"us-central1\",\n",
    "):\n",
    "    # The AI Platform services require regional API endpoints.\n",
    "    client_options = {\"api_endpoint\": f\"{location}-aiplatform.googleapis.com\"}\n",
    "    # Initialize client that will be used to create and send requests.\n",
    "    # This client only needs to be created once, and can be reused for multiple requests.\n",
    "    client = aiplatform.gapic.PredictionServiceClient(client_options=client_options)\n",
    "    parameters_dict = {}\n",
    "    parameters = json_format.ParseDict(parameters_dict, Value())\n",
    "    endpoint = client.endpoint_path(\n",
    "        project=project, location=location, endpoint=endpoint_id\n",
    "    )\n",
    "    response = client.predict(\n",
    "        endpoint=endpoint, instances=instances, parameters=parameters\n",
    "    )\n",
    "    return response.predictions, response.deployed_model_id\n",
    "\n",
    "\n",
    "def load_img(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    return Image.fromarray(np.uint8(img)).convert(\"RGB\")\n",
    "\n",
    "\n",
    "def display_image(image):\n",
    "    _ = plt.figure(figsize=(20, 15))\n",
    "    plt.grid(False)\n",
    "    plt.imshow(image)\n",
    "\n",
    "\n",
    "def get_prediction_instances(test_filepath, new_width=-1):\n",
    "    if new_width <= 0:\n",
    "        with tf.io.gfile.GFile(test_filepath, \"rb\") as input_file:\n",
    "            encoded_string = base64.b64encode(input_file.read()).decode(\"utf-8\")\n",
    "    else:\n",
    "        img = load_img(test_filepath)\n",
    "        width, height = img.size\n",
    "        print(\"original input image size: \", width, \" , \", height)\n",
    "        new_height = int(height * new_width / width)\n",
    "        new_img = img.resize((new_width, new_height))\n",
    "        print(\"resized input image size: \", new_width, \" , \", new_height)\n",
    "        buffered = BytesIO()\n",
    "        new_img.save(buffered, format=\"JPEG\")\n",
    "        encoded_string = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "    instances = [\n",
    "        {\n",
    "            \"encoded_image\": {\"b64\": encoded_string},\n",
    "        }\n",
    "    ]\n",
    "    return instances\n",
    "\n",
    "\n",
    "def get_label_map(label_map_yaml_filepath):\n",
    "    with tf.io.gfile.GFile(label_map_yaml_filepath, \"rb\") as input_file:\n",
    "        label_map = yaml.safe_load(input_file.read())\n",
    "    return label_map\n",
    "\n",
    "\n",
    "def get_best_trial(model_dir, max_trial_count, evaluation_metric):\n",
    "    best_trial_dir = \"\"\n",
    "    best_trial_evaluation_results = {}\n",
    "    best_performance = -1\n",
    "\n",
    "    for i in range(max_trial_count):\n",
    "        current_trial = i + 1\n",
    "        current_trial_dir = os.path.join(model_dir, \"trial_\" + str(current_trial))\n",
    "        current_trial_best_ckpt_dir = os.path.join(current_trial_dir, \"best_ckpt\")\n",
    "        current_trial_best_ckpt_evaluation_filepath = os.path.join(\n",
    "            current_trial_best_ckpt_dir, \"info.json\"\n",
    "        )\n",
    "        with tf.io.gfile.GFile(current_trial_best_ckpt_evaluation_filepath, \"rb\") as f:\n",
    "            eval_metric_results = json.load(f)\n",
    "            current_performance = eval_metric_results[evaluation_metric]\n",
    "            if current_performance > best_performance:\n",
    "                best_performance = current_performance\n",
    "                best_trial_dir = current_trial_dir\n",
    "                best_trial_evaluation_results = eval_metric_results\n",
    "    return best_trial_dir, best_trial_evaluation_results\n",
    "\n",
    "\n",
    "def draw_bounding_box_on_image(\n",
    "    image, ymin, xmin, ymax, xmax, color, font, thickness=4, display_str_list=()\n",
    "):\n",
    "    \"\"\"Adds a bounding box to an image.\"\"\"\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    im_width, im_height = image.size\n",
    "    (left, right, top, bottom) = (\n",
    "        xmin * im_width,\n",
    "        xmax * im_width,\n",
    "        ymin * im_height,\n",
    "        ymax * im_height,\n",
    "    )\n",
    "    draw.line(\n",
    "        [(left, top), (left, bottom), (right, bottom), (right, top), (left, top)],\n",
    "        width=thickness,\n",
    "        fill=color,\n",
    "    )\n",
    "\n",
    "    # If the total height of the display strings added to the top of the bounding\n",
    "    # box exceeds the top of the image, stack the strings below the bounding box\n",
    "    # instead of above.\n",
    "    display_str_heights = [font.getsize(ds)[1] for ds in display_str_list]\n",
    "    # Each display_str has a top and bottom margin of 0.05x.\n",
    "    total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n",
    "\n",
    "    if top > total_display_str_height:\n",
    "        text_bottom = top\n",
    "    else:\n",
    "        text_bottom = top + total_display_str_height\n",
    "    # Reverse list and print from bottom to top.\n",
    "    for display_str in display_str_list[::-1]:\n",
    "        text_width, text_height = font.getsize(display_str)\n",
    "        margin = np.ceil(0.05 * text_height)\n",
    "        draw.rectangle(\n",
    "            [\n",
    "                (left, text_bottom - text_height - 2 * margin),\n",
    "                (left + text_width, text_bottom),\n",
    "            ],\n",
    "            fill=color,\n",
    "        )\n",
    "        draw.text(\n",
    "            (left + margin, text_bottom - text_height - margin),\n",
    "            display_str,\n",
    "            fill=\"black\",\n",
    "            font=font,\n",
    "        )\n",
    "        text_bottom -= text_height - 2 * margin\n",
    "\n",
    "\n",
    "def draw_boxes(image, boxes, class_names, scores, max_boxes=40, min_score=0.05):\n",
    "    \"\"\"Overlay labeled boxes on an image with formatted scores and label names.\"\"\"\n",
    "    colors = list(ImageColor.colormap.values())\n",
    "    try:\n",
    "        font = ImageFont.truetype(\n",
    "            \"/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Regular.ttf\", 25\n",
    "        )\n",
    "    except OSError:\n",
    "        print(\"Font not found, using default font.\")\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    for i in range(min(len(boxes), max_boxes)):\n",
    "        if scores[i] >= min_score:\n",
    "            ymin, xmin, ymax, xmax = boxes[i]\n",
    "            display_str = \"{}: {}%\".format(class_names[i], int(100 * scores[i]))\n",
    "            color = colors[hash(class_names[i]) % len(colors)]\n",
    "            draw_bounding_box_on_image(\n",
    "                image,\n",
    "                ymin,\n",
    "                xmin,\n",
    "                ymax,\n",
    "                xmax,\n",
    "                color,\n",
    "                font,\n",
    "                display_str_list=[display_str],\n",
    "            )\n",
    "    return image\n",
    "\n",
    "\n",
    "def upload_checkpoint_to_gcs(checkpoint_url):\n",
    "    filename = os.path.basename(checkpoint_url)\n",
    "    checkpoint_name = filename.replace(\".tar.gz\", \"\")\n",
    "    print(\"Download checkpoint from\", checkpoint_url, \"and store to\", CHECKPOINT_BUCKET)\n",
    "    ! wget $checkpoint_url -O $filename\n",
    "    ! mkdir -p $checkpoint_name\n",
    "    ! tar -xvzf $filename -C $checkpoint_name\n",
    "\n",
    "    # Search for relative path to the checkpoint.\n",
    "    checkpoint_path = None\n",
    "    for root, dirs, files in os.walk(checkpoint_name):\n",
    "        for file in files:\n",
    "            if file.endswith(\".index\"):\n",
    "                checkpoint_path = os.path.join(root, os.path.splitext(file)[0])\n",
    "                checkpoint_path = os.path.relpath(checkpoint_path, checkpoint_name)\n",
    "                break\n",
    "\n",
    "    ! gsutil cp -r $checkpoint_name $CHECKPOINT_BUCKET/\n",
    "    checkpoint_uri = os.path.join(CHECKPOINT_BUCKET, checkpoint_name, checkpoint_path)\n",
    "    print(\"Checkpoint uploaded to\", checkpoint_uri)\n",
    "    return checkpoint_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train new model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare input data for training\n",
    "\n",
    "Prepare data in the format as described [here](https://cloud.google.com/vertex-ai/docs/image-data/classification/prepare-data), and then convert them to the training formats as below:\n",
    "\n",
    "* `input_file_path`: The input file path for preparing data.\n",
    "* `input_file_type`: The input file type, such as csv or jsonl.\n",
    "* `split_ratio`: The proportion of data to split into train/validation/test.\n",
    "* `num_shard`: The number of shards for train/validation/test.\n",
    "* `output_dir`: The output directory, which will contain prepared train/test/validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This job will convert input data as training format, with given split ratios\n",
    "# and number of shards on train/test/validation.\n",
    "data_converter_job_name = get_job_name_with_datetime(\n",
    "    DATA_CONVERTER_JOB_PREFIX + \"_\" + OBJECTIVE\n",
    ")\n",
    "\n",
    "input_file_path = \"\"  # @param {type:\"string\"}\n",
    "input_file_type = \"csv\"  # @param ['csv', 'jsonl', 'coco_json']\n",
    "split_ratio = \"0.8,0.1,0.1\"\n",
    "num_shard = \"10,10,10\"\n",
    "data_converter_output_dir = os.path.join(BUCKET_URI, data_converter_job_name)\n",
    "\n",
    "\n",
    "worker_pool_specs = [\n",
    "    {\n",
    "        \"machine_spec\": {\n",
    "            \"machine_type\": DATA_CONVERTER_MACHINE_TYPE,\n",
    "        },\n",
    "        \"replica_count\": 1,\n",
    "        \"container_spec\": {\n",
    "            \"image_uri\": DATA_CONVERTER_CONTAINER,\n",
    "            \"command\": [],\n",
    "            \"args\": [\n",
    "                \"--input_file_path=%s\" % input_file_path,\n",
    "                \"--input_file_type=%s\" % input_file_type,\n",
    "                \"--objective=%s\" % OBJECTIVE,\n",
    "                \"--num_shard=%s\" % num_shard,\n",
    "                \"--split_ratio=%s\" % split_ratio,\n",
    "                \"--output_dir=%s\" % data_converter_output_dir,\n",
    "            ],\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "data_converter_custom_job = aiplatform.CustomJob(\n",
    "    display_name=data_converter_job_name,\n",
    "    project=PROJECT_ID,\n",
    "    worker_pool_specs=worker_pool_specs,\n",
    "    staging_bucket=STAGING_BUCKET,\n",
    ")\n",
    "\n",
    "data_converter_custom_job.run()\n",
    "\n",
    "input_train_data_path = os.path.join(data_converter_output_dir, \"train.tfrecord*\")\n",
    "input_validation_data_path = os.path.join(data_converter_output_dir, \"val.tfrecord*\")\n",
    "label_map_path = os.path.join(data_converter_output_dir, \"label_map.yaml\")\n",
    "print(\"input_train_data_path for training: \", input_train_data_path)\n",
    "print(\"input_validation_data_path for training: \", input_validation_data_path)\n",
    "print(\"label_map_path for prediction: \", label_map_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud.aiplatform import hyperparameter_tuning as hpt\n",
    "\n",
    "label_map = get_label_map(label_map_path)\n",
    "num_classes = len(label_map[\"label_map\"]) + 1\n",
    "\n",
    "# Input train and validation datasets can be found from the section above\n",
    "# `Convert input data for training`.\n",
    "# Set prepared datasets if exists.\n",
    "# input_train_data_path = ''\n",
    "# input_validation_data_path = ''\n",
    "\n",
    "# Refer to https://github.com/tensorflow/models/blob/master/official/vision/MODEL_GARDEN.md\n",
    "# for more model details.\n",
    "experiment = \"retinanet_spinenet96\"  # @param ['retinanet_spinenet49', \"retinanet_spinenet96\", 'retinanet_spinenet143', 'scaled_yolo_v4', 'yolov7']\n",
    "\n",
    "train_job_name = get_job_name_with_datetime(TRAINING_JOB_PREFIX + \"_\" + OBJECTIVE)\n",
    "model_dir = os.path.join(BUCKET_URI, train_job_name)\n",
    "\n",
    "# The arguments here are mainly for test purposes. Please update them\n",
    "# to get better performances.\n",
    "common_args = {\n",
    "    \"input_train_data_path\": input_train_data_path,\n",
    "    \"input_validation_data_path\": input_validation_data_path,\n",
    "    \"objective\": OBJECTIVE,\n",
    "    \"model_dir\": model_dir,\n",
    "    \"num_classes\": num_classes,\n",
    "    \"global_batch_size\": 2,\n",
    "    \"prefetch_buffer_size\": 6,\n",
    "    \"train_steps\": 2000,\n",
    "    \"input_size\": \"1024,1024\",\n",
    "}\n",
    "\n",
    "experiment_container_args_dict = {\n",
    "    # retinanet_spinenet49 experiment args.\n",
    "    \"retinanet_spinenet49\": dict(\n",
    "        common_args,\n",
    "        **{\n",
    "            \"experiment\": \"retinanet_spinenet_coco\",\n",
    "            \"config_file\": TRAIN_SPINENET49_CONFIG,\n",
    "            \"anchor_size\": 4,\n",
    "        },\n",
    "    ),\n",
    "    # retinanet_spinenet96 experiment args.\n",
    "    \"retinanet_spinenet96\": dict(\n",
    "        common_args,\n",
    "        **{\n",
    "            \"experiment\": \"retinanet_spinenet_coco\",\n",
    "            \"config_file\": TRAIN_SPINENET96_CONFIG,\n",
    "            \"anchor_size\": 4,\n",
    "        },\n",
    "    ),\n",
    "    # retinanet_spinenet143 experiment args.\n",
    "    \"retinanet_spinenet143\": dict(\n",
    "        common_args,\n",
    "        **{\n",
    "            \"experiment\": \"retinanet_spinenet_coco\",\n",
    "            \"config_file\": TRAIN_SPINENET143_CONFIG,\n",
    "            \"anchor_size\": 4,\n",
    "        },\n",
    "    ),\n",
    "    # scaled_yolo_v4 experiment args.\n",
    "    \"scaled_yolo_v4\": dict(\n",
    "        common_args,\n",
    "        **{\n",
    "            \"experiment\": \"scaled_yolo\",\n",
    "            \"config_file\": TRAIN_YOLOV4_CONFIG,\n",
    "            \"init_checkpoint\": \"https://storage.googleapis.com/tf_model_garden/vision/yolo/scaled-yolov4/scaled-yolov4-l-p6-i1280.tar.gz\",\n",
    "            \"input_size\": \"1280,1280\",\n",
    "        },\n",
    "    ),\n",
    "    # yolov7 experiment args.\n",
    "    \"yolov7\": dict(\n",
    "        common_args,\n",
    "        **{\n",
    "            \"experiment\": \"coco_yolov7\",\n",
    "            \"config_file\": TRAIN_YOLOV7_CONFIG,\n",
    "            \"init_checkpoint\": \"https://storage.googleapis.com/tf_model_garden/vision/yolo/yolov7/yolov7.tar.gz\",\n",
    "            \"input_size\": \"640,640\",\n",
    "        },\n",
    "    ),\n",
    "}\n",
    "experiment_container_args = experiment_container_args_dict[experiment]\n",
    "\n",
    "# Copy checkpoint to GCS bucket if specified.\n",
    "init_checkpoint = experiment_container_args.get(\"init_checkpoint\")\n",
    "if init_checkpoint:\n",
    "    experiment_container_args[\"init_checkpoint\"] = upload_checkpoint_to_gcs(\n",
    "        init_checkpoint\n",
    "    )\n",
    "if \"yolov7\" in experiment:\n",
    "    TRAIN_CONTAINER_URI = f\"{REGION_PREFIX}-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/tfvision-oss-v2\"\n",
    "\n",
    "params_override = \"runtime.num_gpus=%s\" % TRAIN_NUM_GPU\n",
    "eval_params_override = \"runtime.num_gpus=1,runtime.distribution_strategy=mirrored\"\n",
    "worker_pool_specs = [\n",
    "    {\n",
    "        \"machine_spec\": {\n",
    "            \"machine_type\": TRAIN_MACHINE_TYPE,\n",
    "            \"accelerator_type\": TRAIN_ACCELERATOR_TYPE,\n",
    "            \"accelerator_count\": TRAIN_NUM_GPU,\n",
    "        },\n",
    "        \"replica_count\": 1,\n",
    "        \"container_spec\": {\n",
    "            \"image_uri\": TRAIN_CONTAINER_URI,\n",
    "            \"args\": [\n",
    "                \"--mode=train\",\n",
    "                \"--params_override=%s\" % params_override,\n",
    "            ]\n",
    "            + [\"--{}={}\".format(k, v) for k, v in experiment_container_args.items()],\n",
    "        },\n",
    "    },\n",
    "    {},\n",
    "    {},\n",
    "    {\n",
    "        \"machine_spec\": {\n",
    "            \"machine_type\": \"n1-highmem-4\",\n",
    "            \"accelerator_count\": 0,\n",
    "        },\n",
    "        \"replica_count\": 1,\n",
    "        \"container_spec\": {\n",
    "            \"image_uri\": TRAIN_CONTAINER_URI,\n",
    "            \"args\": [\n",
    "                \"--mode=continuous_eval\",\n",
    "                \"--params_override=%s\" % eval_params_override,\n",
    "            ]\n",
    "            + [\"--{}={}\".format(k, v) for k, v in experiment_container_args.items()],\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "metric_spec = {\"model_performance\": \"maximize\"}\n",
    "\n",
    "# LEARNING_RATES = [0.001, 0.01]\n",
    "LEARNING_RATES = [0.01]\n",
    "# Models will be trained with each learning rate separately and max trial count is the number of learning rates.\n",
    "MAX_TRIAL_COUNT = len(LEARNING_RATES)\n",
    "parameter_spec = {\n",
    "    \"learning_rate\": hpt.DiscreteParameterSpec(values=LEARNING_RATES, scale=\"linear\"),\n",
    "}\n",
    "\n",
    "print(worker_pool_specs, metric_spec, parameter_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_custom_job = aiplatform.CustomJob(\n",
    "    display_name=train_job_name,\n",
    "    project=PROJECT_ID,\n",
    "    worker_pool_specs=worker_pool_specs,\n",
    "    staging_bucket=STAGING_BUCKET,\n",
    ")\n",
    "\n",
    "train_hpt_job = aiplatform.HyperparameterTuningJob(\n",
    "    display_name=train_job_name,\n",
    "    custom_job=train_custom_job,\n",
    "    metric_spec=metric_spec,\n",
    "    parameter_spec=parameter_spec,\n",
    "    max_trial_count=MAX_TRIAL_COUNT,\n",
    "    parallel_trial_count=1,\n",
    "    project=PROJECT_ID,\n",
    "    search_algorithm=None,\n",
    ")\n",
    "\n",
    "train_hpt_job.run()\n",
    "\n",
    "print(\"experiment is: \", experiment)\n",
    "print(\"model_dir is: \", model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This job will export models from TF checkpoints to TF saved model format.\n",
    "# model_dir is from the section above.\n",
    "best_trial_dir, best_trial_evaluation_results = get_best_trial(\n",
    "    model_dir, MAX_TRIAL_COUNT, EVALUATION_METRIC\n",
    ")\n",
    "print(\"best_trial_dir: \", best_trial_dir)\n",
    "print(\"best_trial_evaluation_results: \", best_trial_evaluation_results)\n",
    "\n",
    "worker_pool_specs = [\n",
    "    {\n",
    "        \"machine_spec\": {\n",
    "            \"machine_type\": EXPORT_MACHINE_TYPE,\n",
    "        },\n",
    "        \"replica_count\": 1,\n",
    "        \"container_spec\": {\n",
    "            \"image_uri\": EXPORT_CONTAINER_URI,\n",
    "            \"command\": [],\n",
    "            \"args\": [\n",
    "                \"--objective=%s\" % OBJECTIVE,\n",
    "                \"--input_image_size=1024,1024\",\n",
    "                \"--experiment=%s\" % experiment_container_args[\"experiment\"],\n",
    "                \"--config_file=%s/params.yaml\" % best_trial_dir,\n",
    "                \"--checkpoint_path=%s/best_ckpt\" % best_trial_dir,\n",
    "                \"--export_dir=%s/best_model\" % model_dir,\n",
    "            ],\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "model_export_name = get_job_name_with_datetime(EXPORT_JOB_PREFIX + \"_\" + OBJECTIVE)\n",
    "model_export_custom_job = aiplatform.CustomJob(\n",
    "    display_name=model_export_name,\n",
    "    project=PROJECT_ID,\n",
    "    worker_pool_specs=worker_pool_specs,\n",
    "    staging_bucket=STAGING_BUCKET,\n",
    ")\n",
    "\n",
    "\n",
    "model_export_custom_job.run()\n",
    "\n",
    "print(\"best model is saved to: \", os.path.join(model_dir, \"best_model\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undeploy model and delete endpoint.\n",
    "# endpoint.delete(force=True)\n",
    "# Delete models.\n",
    "# model.delete()\n",
    "# Delete custom and hpt jobs.\n",
    "if data_converter_custom_job.list(filter=f'display_name=\"{data_converter_job_name}\"'):\n",
    "    data_converter_custom_job.delete()\n",
    "if train_hpt_job.list(filter=f'display_name=\"{train_job_name}\"'):\n",
    "    train_hpt_job.delete()\n",
    "if model_export_custom_job.list(filter=f'display_name=\"{model_export_name}\"'):\n",
    "    model_export_custom_job.delete()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
